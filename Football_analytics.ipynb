{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Football analytics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMFUXJJGkFG4X3TDNhDIlpT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teoad95/Sport-analytics/blob/main/Football_analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxlWaD2h0kgJ"
      },
      "source": [
        "<h1>Football analytics using AI techniques</h1>\n",
        "<p> </p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R1xsZAg41zp"
      },
      "source": [
        "import cv2\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1DrVe9g5VYE"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwfvugcY1W9-",
        "outputId": "d16a3525-ce18-4d4e-f691-3a67019d9bcc"
      },
      "source": [
        "pip install pytube"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.7/dist-packages (10.9.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "I1VnEgho9qTI",
        "outputId": "3c145624-1f0e-475f-fcce-1ac1ba43bddf"
      },
      "source": [
        "pip install torch==1.8.1"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/74/6fc9dee50f7c93d6b7d9644554bdc9692f3023fa5d1de779666e6bf8ae76/torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1MB)\n",
            "\u001b[K     |████████████████████████████████| 804.1MB 16kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.7.4.3)\n",
            "\u001b[31mERROR: torchvision 0.10.0+cu102 has requirement torch==1.9.0, but you'll have torch 1.8.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.10.0 has requirement torch==1.9.0, but you'll have torch 1.8.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "Successfully installed torch-1.8.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "J7UfGKpk_hZY",
        "outputId": "41d54db3-a61d-4d3e-9446-251ce36367ff"
      },
      "source": [
        "pip install torchvision==0.9.1"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchvision==0.9.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/8a/82062a33b5eb7f696bf23f8ccf04bf6fc81d1a4972740fb21c2569ada0a6/torchvision-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (17.4MB)\n",
            "\u001b[K     |████████████████████████████████| 17.4MB 204kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1) (1.19.5)\n",
            "Collecting torch==1.8.1\n",
            "  Using cached https://files.pythonhosted.org/packages/56/74/6fc9dee50f7c93d6b7d9644554bdc9692f3023fa5d1de779666e6bf8ae76/torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchvision==0.9.1) (3.7.4.3)\n",
            "\u001b[31mERROR: torchtext 0.10.0 has requirement torch==1.9.0, but you'll have torch 1.8.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.9.0\n",
            "    Uninstalling torch-1.9.0:\n",
            "      Successfully uninstalled torch-1.9.0\n",
            "  Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "Successfully installed torch-1.8.1 torchvision-0.9.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchvision"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFpCZHQt1Xdm"
      },
      "source": [
        "##1 Generate dataset\n",
        "For dataset generation (frame pictures) we created a function which given a youtube link, downloads the video and split it into frames every 0.5 sec."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VWENPJS0kT5",
        "outputId": "1cc22f48-674d-4405-82f3-806651d55dfa"
      },
      "source": [
        "from util_funs import get_frames_from_youtube_video\n",
        "get_frames_from_youtube_video('https://www.youtube.com/watch?v=TeTQO5DgOXI')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded /content/Videos/Highlights Real Madrid vs FC Barcelona (2-1).mp4, in location Videos correctly!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvClhYhg50W5"
      },
      "source": [
        "image_location = '/content/Images/Highlights Real Madrid vs FC Barcelona (2-1)/frame53.jpg'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xovQKiM-4WAn"
      },
      "source": [
        "##2 Detect players\n",
        "For this task we used the pre-trained YOLO neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rk9VTL0r4VQH",
        "outputId": "5aa65faf-7a78-4081-8e08-92e25c529541"
      },
      "source": [
        "# Load model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m torchvision>=0.8.1 not found and is required by YOLOv5, attempting auto-update...\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (0.10.0+cu102)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.8.1) (7.1.2)\n",
            "Collecting torch==1.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/d2/a9/b3cea4a97ffabd6639e71608814dbd08081e202e8ac9580250273c0541ff/torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.8.1) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchvision>=0.8.1) (3.7.4.3)\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.8.1\n",
            "    Uninstalling torch-1.8.1:\n",
            "      Successfully uninstalled torch-1.8.1\n",
            "Successfully installed torch-1.9.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /root/.cache/torch/hub/ultralytics_yolov5_master/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "YOLOv5 🚀 2021-7-6 torch 1.8.1+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7266973 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IopcNWZ35CTG"
      },
      "source": [
        "img = cv2.imread(image_location, cv2.IMREAD_COLOR)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "Wfh2Qb3T5OSC",
        "outputId": "bd57c045-5a86-4f2a-ca28-c047f4936285"
      },
      "source": [
        "from util_funs import plot_bb_on_img\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# inference\n",
        "results = model(img, size=640)  # includes NMS\n",
        "boxes = results.pandas().xyxy[0]\n",
        "\n",
        "# plot bounding boxes\n",
        "cv2_img_bb = plot_bb_on_img(img, boxes, tolerance=0.3)\n",
        "cv2_img_bb = cv2.cvtColor(cv2_img_bb, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.imshow(cv2_img_bb[:,:,::-1])\n",
        "\n",
        "# cv2.imshow(\"frame\", cv2_img_bb)\n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()\n",
        "\n",
        "print(\"--- %.2f seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-603007483ebe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# includes NMS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mgrad_input\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mgrad_output\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mare\u001b[0m \u001b[0mtuples\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcontain\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mrespect\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0mrespectively\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mhook\u001b[0m \u001b[0mshould\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0;32mnot\u001b[0m \u001b[0mmodify\u001b[0m \u001b[0mits\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcan\u001b[0m \u001b[0moptionally\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mrespect\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplace\u001b[0m \u001b[0mof\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mgrad_input\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, imgs, size, augment, profile)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;31m# Post-process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_max_suppression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_thres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miou\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_det\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_det\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# NMS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0mscale_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/root/.cache/torch/hub/ultralytics_yolov5_master/utils/general.py\u001b[0m in \u001b[0;36mnon_max_suppression\u001b[0;34m(prediction, conf_thres, iou_thres, classes, agnostic, multi_label, labels, max_det)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0magnostic\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmax_wh\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# boxes (offset by class), scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_thres\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# NMS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_det\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# limit detections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_det\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/ops/boxes.py\u001b[0m in \u001b[0;36mnms\u001b[0;34m(boxes, scores, iou_threshold)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mby\u001b[0m \u001b[0mNMS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecreasing\u001b[0m \u001b[0morder\u001b[0m \u001b[0mof\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0m_assert_has_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/extension.py\u001b[0m in \u001b[0;36m_assert_has_ops\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_has_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         raise RuntimeError(\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;34m\"Couldn't load custom C++ ops. This can happen if your PyTorch and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;34m\"torchvision versions are incompatible, or if you had errors while compiling \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;34m\"torchvision from source. For further information on the compatible versions, check \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Couldn't load custom C++ ops. This can happen if your PyTorch and torchvision versions are incompatible, or if you had errors while compiling torchvision from source. For further information on the compatible versions, check https://github.com/pytorch/vision#installation for the compatibility matrix. Please check your PyTorch version with torch.__version__ and your torchvision version with torchvision.__version__ and verify if they are compatible, and if not please reinstall torchvision so that it matches your PyTorch install."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BapgshM68oRm"
      },
      "source": [
        "img = Image.open(image_location)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "M1sMB5eA5w9G",
        "outputId": "1493b279-a615-4223-b95d-283f8ea9be70"
      },
      "source": [
        "from PIL import Image\n",
        "from util_funs import sliding_window\n",
        "import math\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(25, 25))\n",
        "\n",
        "#img = Image.open(image_location)\n",
        "img_width, img_height = img.size\n",
        "step_size= 64\n",
        "window_size = (256,256)\n",
        "\n",
        "columns = math.ceil(int(img_width / step_size))-3\n",
        "rows = math.ceil(img_height / step_size)\n",
        "\n",
        "ax = []\n",
        "\n",
        "boxes_df = pd.DataFrame(columns = ['xmin','ymin','xmax','ymax','confidence','class','name','centerx','centery'])\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for i,(box,img) in enumerate(sliding_window(img, step_size, window_size)):\n",
        "    ax.append(fig.add_subplot(rows, columns, i+1))\n",
        " \n",
        "    # inference\n",
        "    results = model(img, size=320)  # includes NMS\n",
        "    boxes = results.pandas().xyxy[0]\n",
        "    \n",
        "  \n",
        "    # plot bounding boxes\n",
        "    cv2_img_bb = plot_bb_on_img(img, boxes)\n",
        "    cv2_img_bb = cv2.cvtColor(cv2_img_bb, cv2.COLOR_BGR2RGB)\n",
        "    plt.title(box)\n",
        "    plt.imshow(cv2_img_bb)\n",
        "    plt.axis('off')\n",
        "    \n",
        "    # project to starting image\n",
        "    boxes.xmin = boxes.xmin+box[0]\n",
        "    boxes.xmax = boxes.xmax+box[0]\n",
        "\n",
        "    boxes.ymin = boxes.ymin+box[1]\n",
        "    boxes.ymax = boxes.ymax+box[1]\n",
        "\n",
        "    boxes['centerx'] = boxes.xmax - (boxes.xmax-boxes.xmin)/2\n",
        "    boxes['centery'] = boxes.ymax - (boxes.ymax-boxes.ymin)/2\n",
        "    boxes['distance'] = np.sqrt(boxes.centerx*boxes.centerx + boxes.centery*boxes.centery)\n",
        "    \n",
        "    boxes_df = boxes_df.append(boxes, ignore_index=True)\n",
        "    \n",
        "boxes_df = keep_unique_objects_df(boxes_df)\n",
        "\n",
        "                \n",
        "                \n",
        "print(\"--- %.2f seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-957842c60760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# includes NMS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, imgs, size, augment, profile)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexif_transpose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                 \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexif_transpose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'filename'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# image in CHW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Image' object has no attribute 'filename'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABaAAAAFKCAYAAADrMPg/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAU70lEQVR4nO3dX4il913H8c+32aZCWyu4K5TsxgTcWtdWaB1ipRcWWmWTi90LRRIoWgndG1P8UwopLa3Eq7aoIKTVFUttwcbYCxkwkguNFIopmVINTUrKELXZKGTbxtwUm0a/XsypTKe7Oyeb853dk7xeEDjP8/zmnO/Vj9l3nnlOdXcAAAAAAGDVXnalBwAAAAAA4MVJgAYAAAAAYIQADQAAAADACAEaAAAAAIARAjQAAAAAACMEaAAAAAAARuwboKvqk1X1VFV95SLXq6r+uKq2q+rhqnrz6scEAAAAAGDdLHMH9KeSnLzE9ZuTHF/8dybJJ174WAAAAAAArLt9A3R3fz7Jty6x5HSST/eOB5P8SFW9dlUDAgAAAACwng6t4D2uS/LEruNzi3P/uXdhVZ3Jzl3SeeUrX/mzr3/961fw8QAAAAAATPnSl770je4+cjk/u4oAvbTuPpvkbJJsbGz01tbWQX48AAAAAADPU1X9++X+7DLPgN7Pk0mO7To+ujgHAAAAAMBL2CoC9GaSX6sdb0nyTHf/wOM3AAAAAAB4adn3ERxV9dkkb0tyuKrOJflwkpcnSXf/SZL7ktySZDvJt5P8xtSwAAAAAACsj30DdHffts/1TvKbK5sIAAAAAIAXhVU8ggMAAAAAAH6AAA0AAAAAwAgBGgAAAACAEQI0AAAAAAAjBGgAAAAAAEYI0AAAAAAAjBCgAQAAAAAYIUADAAAAADBCgAYAAAAAYIQADQAAAADACAEaAAAAAIARAjQAAAAAACMEaAAAAAAARgjQAAAAAACMEKABAAAAABghQAMAAAAAMEKABgAAAABghAANAAAAAMAIARoAAAAAgBECNAAAAAAAIwRoAAAAAABGCNAAAAAAAIwQoAEAAAAAGCFAAwAAAAAwQoAGAAAAAGCEAA0AAAAAwAgBGgAAAACAEQI0AAAAAAAjBGgAAAAAAEYI0AAAAAAAjBCgAQAAAAAYIUADAAAAADBCgAYAAAAAYIQADQAAAADACAEaAAAAAIARAjQAAAAAACMEaAAAAAAARgjQAAAAAACMEKABAAAAABghQAMAAAAAMEKABgAAAABghAANAAAAAMAIARoAAAAAgBECNAAAAAAAIwRoAAAAAABGCNAAAAAAAIwQoAEAAAAAGCFAAwAAAAAwQoAGAAAAAGCEAA0AAAAAwIilAnRVnayqx6pqu6ruvMD166vqgar6clU9XFW3rH5UAAAAAADWyb4BuqquSXJ3kpuTnEhyW1Wd2LPsg0nu7e43Jbk1ycdXPSgAAAAAAOtlmTugb0qy3d2Pd/ezSe5JcnrPmk7yw4vXr0nyH6sbEQAAAACAdbRMgL4uyRO7js8tzu32e0neWVXnktyX5D0XeqOqOlNVW1W1df78+csYFwAAAACAdbGqLyG8LcmnuvtokluSfKaqfuC9u/tsd29098aRI0dW9NEAAAAAAFyNlgnQTyY5tuv46OLcbrcnuTdJuvufkvxQksOrGBAAAAAAgPW0TIB+KMnxqrqxqq7NzpcMbu5Z8/Ukb0+Sqvqp7ARoz9gAAAAAAHgJ2zdAd/dzSe5Icn+Srya5t7sfqaq7qurUYtl7k7y7qv4lyWeTvKu7e2poAAAAAACufoeWWdTd92XnywV3n/vQrtePJnnrakcDAAAAAGCdrepLCAEAAAAA4PsI0AAAAAAAjBCgAQAAAAAYIUADAAAAADBCgAYAAAAAYIQADQAAAADACAEaAAAAAIARAjQAAAAAACMEaAAAAAAARgjQAAAAAACMEKABAAAAABghQAMAAAAAMEKABgAAAABghAANAAAAAMAIARoAAAAAgBECNAAAAAAAIwRoAAAAAABGCNAAAAAAAIwQoAEAAAAAGCFAAwAAAAAwQoAGAAAAAGCEAA0AAAAAwAgBGgAAAACAEQI0AAAAAAAjBGgAAAAAAEYI0AAAAAAAjBCgAQAAAAAYIUADAAAAADBCgAYAAAAAYIQADQAAAADACAEaAAAAAIARAjQAAAAAACMEaAAAAAAARgjQAAAAAACMEKABAAAAABghQAMAAAAAMEKABgAAAABghAANAAAAAMAIARoAAAAAgBECNAAAAAAAIwRoAAAAAABGCNAAAAAAAIwQoAEAAAAAGCFAAwAAAAAwQoAGAAAAAGCEAA0AAAAAwAgBGgAAAACAEQI0AAAAAAAjBGgAAAAAAEYI0AAAAAAAjFgqQFfVyap6rKq2q+rOi6z51ap6tKoeqaq/XO2YAAAAAACsm0P7Laiqa5LcneQXk5xL8lBVbXb3o7vWHE/y/iRv7e6nq+rHpgYGAAAAAGA9LHMH9E1Jtrv78e5+Nsk9SU7vWfPuJHd399NJ0t1PrXZMAAAAAADWzTIB+rokT+w6Prc4t9vrkryuqr5QVQ9W1clVDQgAAAAAwHra9xEcz+N9jid5W5KjST5fVW/s7v/avaiqziQ5kyTXX3/9ij4aAAAAAICr0TJ3QD+Z5Niu46OLc7udS7LZ3d/t7n9N8rXsBOnv091nu3ujuzeOHDlyuTMDAAAAALAGlgnQDyU5XlU3VtW1SW5Nsrlnzd9k5+7nVNXh7DyS4/EVzgkAAAAAwJrZN0B393NJ7khyf5KvJrm3ux+pqruq6tRi2f1JvllVjyZ5IMn7uvubU0MDAAAAAHD1q+6+Ih+8sbHRW1tbV+SzAQAAAABYTlV9qbs3Ludnl3kEBwAAAAAAPG8CNAAAAAAAIwRoAAAAAABGCNAAAAAAAIwQoAEAAAAAGCFAAwAAAAAwQoAGAAAAAGCEAA0AAAAAwAgBGgAAAACAEQI0AAAAAAAjBGgAAAAAAEYI0AAAAAAAjBCgAQAAAAAYIUADAAAAADBCgAYAAAAAYIQADQAAAADACAEaAAAAAIARAjQAAAAAACMEaAAAAAAARgjQAAAAAACMEKABAAAAABghQAMAAAAAMEKABgAAAABghAANAAAAAMAIARoAAAAAgBECNAAAAAAAIwRoAAAAAABGCNAAAAAAAIwQoAEAAAAAGCFAAwAAAAAwQoAGAAAAAGCEAA0AAAAAwAgBGgAAAACAEQI0AAAAAAAjBGgAAAAAAEYI0AAAAAAAjBCgAQAAAAAYIUADAAAAADBCgAYAAAAAYIQADQAAAADACAEaAAAAAIARAjQAAAAAACMEaAAAAAAARgjQAAAAAACMEKABAAAAABghQAMAAAAAMEKABgAAAABghAANAAAAAMAIARoAAAAAgBECNAAAAAAAI5YK0FV1sqoeq6rtqrrzEut+uaq6qjZWNyIAAAAAAOto3wBdVdckuTvJzUlOJLmtqk5cYN2rk/xWki+uekgAAAAAANbPMndA35Rku7sf7+5nk9yT5PQF1v1+ko8k+e8VzgcAAAAAwJpaJkBfl+SJXcfnFuf+X1W9Ocmx7v7bFc4GAAAAAMAae8FfQlhVL0vyh0neu8TaM1W1VVVb58+ff6EfDQAAAADAVWyZAP1kkmO7jo8uzn3Pq5O8Ick/VtW/JXlLks0LfRFhd5/t7o3u3jhy5MjlTw0AAAAAwFVvmQD9UJLjVXVjVV2b5NYkm9+72N3PdPfh7r6hu29I8mCSU929NTIxAAAAAABrYd8A3d3PJbkjyf1Jvprk3u5+pKruqqpT0wMCAAAAALCeDi2zqLvvS3LfnnMfusjat73wsQAAAAAAWHcv+EsIAQAAAADgQgRoAAAAAABGCNAAAAAAAIwQoAEAAAAAGCFAAwAAAAAwQoAGAAAAAGCEAA0AAAAAwAgBGgAAAACAEQI0AAAAAAAjBGgAAAAAAEYI0AAAAAAAjBCgAQAAAAAYIUADAAAAADBCgAYAAAAAYIQADQAAAADACAEaAAAAAIARAjQAAAAAACMEaAAAAAAARgjQAAAAAACMEKABAAAAABghQAMAAAAAMEKABgAAAABghAANAAAAAMAIARoAAAAAgBECNAAAAAAAIwRoAAAAAABGCNAAAAAAAIwQoAEAAAAAGCFAAwAAAAAwQoAGAAAAAGCEAA0AAAAAwAgBGgAAAACAEQI0AAAAAAAjBGgAAAAAAEYI0AAAAAAAjBCgAQAAAAAYIUADAAAAADBCgAYAAAAAYIQADQAAAADACAEaAAAAAIARAjQAAAAAACMEaAAAAAAARgjQAAAAAACMEKABAAAAABghQAMAAAAAMEKABgAAAABghAANAAAAAMAIARoAAAAAgBECNAAAAAAAIwRoAAAAAABGCNAAAAAAAIxYKkBX1cmqeqyqtqvqzgtc/92qerSqHq6qv6+qH1/9qAAAAAAArJN9A3RVXZPk7iQ3JzmR5LaqOrFn2ZeTbHT3zyT5XJKPrnpQAAAAAADWyzJ3QN+UZLu7H+/uZ5Pck+T07gXd/UB3f3tx+GCSo6sdEwAAAACAdbNMgL4uyRO7js8tzl3M7Un+7kIXqupMVW1V1db58+eXnxIAAAAAgLWz0i8hrKp3JtlI8rELXe/us9290d0bR44cWeVHAwAAAABwlTm0xJonkxzbdXx0ce77VNU7knwgyS9093dWMx4AAAAAAOtqmTugH0pyvKpurKprk9yaZHP3gqp6U5I/TXKqu59a/ZgAAAAAAKybfQN0dz+X5I4k9yf5apJ7u/uRqrqrqk4tln0syauS/HVV/XNVbV7k7QAAAAAAeIlY5hEc6e77kty359yHdr1+x4rnAgAAAABgza30SwgBAAAAAOB7BGgAAAAAAEYI0AAAAAAAjBCgAQAAAAAYIUADAAAAADBCgAYAAAAAYIQADQAAAADACAEaAAAAAIARAjQAAAAAACMEaAAAAAAARgjQAAAAAACMEKABAAAAABghQAMAAAAAMEKABgAAAABghAANAAAAAMAIARoAAAAAgBECNAAAAAAAIwRoAAAAAABGCNAAAAAAAIwQoAEAAAAAGCFAAwAAAAAwQoAGAAAAAGCEAA0AAAAAwAgBGgAAAACAEQI0AAAAAAAjBGgAAAAAAEYI0AAAAAAAjBCgAQAAAAAYIUADAAAAADBCgAYAAAAAYIQADQAAAADACAEaAAAAAIARAjQAAAAAACMEaAAAAAAARgjQAAAAAACMEKABAAAAABghQAMAAAAAMEKABgAAAABghAANAAAAAMAIARoAAAAAgBECNAAAAAAAIwRoAAAAAABGCNAAAAAAAIwQoAEAAAAAGCFAAwAAAAAwQoAGAAAAAGCEAA0AAAAAwAgBGgAAAACAEQI0AAAAAAAjBGgAAAAAAEYsFaCr6mRVPVZV21V15wWuv6Kq/mpx/YtVdcOqBwUAAAAAYL3sG6Cr6pokdye5OcmJJLdV1Yk9y25P8nR3/0SSP0rykVUPCgAAAADAelnmDuibkmx39+Pd/WySe5Kc3rPmdJK/WLz+XJK3V1WtbkwAAAAAANbNoSXWXJfkiV3H55L83MXWdPdzVfVMkh9N8o3di6rqTJIzi8PvVNVXLmdogEs4nD17D8AK2FuACfYWYIK9BZjwk5f7g8sE6JXp7rNJziZJVW1198ZBfj7w4mdvASbYW4AJ9hZggr0FmFBVW5f7s8s8guPJJMd2HR9dnLvgmqo6lOQ1Sb55uUMBAAAAALD+lgnQDyU5XlU3VtW1SW5NsrlnzWaSX1+8/pUk/9DdvboxAQAAAABYN/s+gmPxTOc7ktyf5Jokn+zuR6rqriRb3b2Z5M+TfKaqtpN8KzuRej9nX8DcABdjbwEm2FuACfYWYIK9BZhw2XtLuVEZAAAAAIAJyzyCAwAAAAAAnjcBGgAAAACAEeMBuqpOVtVjVbVdVXde4PorquqvFte/WFU3TM8ErL8l9pbfrapHq+rhqvr7qvrxKzEnsF7221t2rfvlquqq2jjI+YD1tMzeUlW/uvjd5ZGq+suDnhFYP0v8m+j6qnqgqr68+HfRLVdiTmB9VNUnq+qpqvrKRa5XVf3xYt95uKrevMz7jgboqromyd1Jbk5yIsltVXViz7Lbkzzd3T+R5I+SfGRyJmD9Lbm3fDnJRnf/TJLPJfnowU4JrJsl95ZU1auT/FaSLx7shMA6WmZvqarjSd6f5K3d/dNJfvvABwXWypK/t3wwyb3d/aYktyb5+MFOCayhTyU5eYnrNyc5vvjvTJJPLPOm03dA35Rku7sf7+5nk9yT5PSeNaeT/MXi9eeSvL2qanguYL3tu7d09wPd/e3F4YNJjh7wjMD6Web3liT5/ez8D/P/PsjhgLW1zN7y7iR3d/fTSdLdTx3wjMD6WWZv6SQ/vHj9miT/cYDzAWuouz+f5FuXWHI6yad7x4NJfqSqXrvf+04H6OuSPLHr+Nzi3AXXdPdzSZ5J8qPDcwHrbZm9Zbfbk/zd6ETAi8G+e8viT8yOdfffHuRgwFpb5veW1yV5XVV9oaoerKpL3XkEkCy3t/xekndW1bkk9yV5z8GMBryIPd8ekyQ5NDYOwFWgqt6ZZCPJL1zpWYD1VlUvS/KHSd51hUcBXnwOZedPWd+Wnb/a+nxVvbG7/+uKTgWsu9uSfKq7/6Cqfj7JZ6rqDd39v1d6MOClZfoO6CeTHNt1fHRx7oJrqupQdv4s5JvDcwHrbZm9JVX1jiQfSHKqu79zQLMB62u/veXVSd6Q5B+r6t+SvCXJpi8iBPaxzO8t55Jsdvd3u/tfk3wtO0Ea4GKW2VtuT3JvknT3PyX5oSSHD2Q64MVqqR6z13SAfijJ8aq6saquzc5D7zf3rNlM8uuL17+S5B+6u4fnAtbbvntLVb0pyZ9mJz57jiKwjEvuLd39THcf7u4buvuG7Dxf/lR3b12ZcYE1scy/if4mO3c/p6oOZ+eRHI8f5JDA2llmb/l6krcnSVX9VHYC9PkDnRJ4sdlM8mu14y1Jnunu/9zvh0YfwdHdz1XVHUnuT3JNkk929yNVdVeSre7eTPLn2fkzkO3sPOT61smZgPW35N7ysSSvSvLXi+81/Xp3n7piQwNXvSX3FoDnZcm95f4kv1RVjyb5nyTv625/FQpc1JJ7y3uT/FlV/U52vpDwXW74Ay6lqj6bnf8pfnjx/PgPJ3l5knT3n2TnefK3JNlO8u0kv7HU+9p7AAAAAACYMP0IDgAAAAAAXqIEaAAAAAAARgjQAAAAAACMEKABAAAAABghQAMAAAAAMEKABgAAAABghAANAAAAAMCI/wMnvqXZFVywcwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1800x1800 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXE3eYcO9bA3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}